{"cells":[{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":1343,"status":"ok","timestamp":1734421710373,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"JdJufkaSMPUE"},"outputs":[],"source":["import faiss\n","import numpy as np\n","from sentence_transformers import SentenceTransformer, util\n","from ollama import chat\n","from ollama import ChatResponse\n","import re\n","import tiktoken\n","\n","# Load the embedding model\n","embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n","em_model = SentenceTransformer(embedding_model, device=\"cuda\")  # Use GPU for encoding\n","\n","# Function to load FAISS index\n","def load_faiss_index(index_file):\n","    \"\"\"Loads the FAISS index from a file.\"\"\"\n","    index = faiss.read_index(index_file)\n","    return index\n","\n","# Function to perform retrieval\n","def retrieve_top_k(query, index, metadata, top_k=5):\n","    \"\"\"\n","    Retrieve top-k similar documents for a given query.\n","\n","    Args:\n","        query (str): The query string.\n","        index (faiss.Index): The FAISS index.\n","        metadata (list[dict]): Metadata corresponding to the embeddings in the index.\n","        top_k (int): Number of top results to retrieve.\n","\n","    Returns:\n","        list[dict]: Top-k metadata entries with similarity scores.\n","    \"\"\"\n","    # Encode the query into an embedding\n","    query_embedding = em_model.encode([query], convert_to_numpy=True)\n","\n","    # Search the FAISS index\n","    distances, indices = index.search(query_embedding, top_k)\n","\n","    # Collect results\n","    results = []\n","    for i, idx in enumerate(indices[0]):\n","        if idx == -1:  # FAISS returns -1 for missing indices\n","            continue\n","        results.append({\n","            \"score\": distances[0][i],\n","            **metadata[idx]\n","        })\n","    return results\n","\n","def truncate_text(text, max_tokens=2000, model_name=\"cl100k_base\"):\n","    \"\"\"\n","    Truncates text from the bottom to fit within a token limit.\n","\n","    Args:\n","        text (str): The text to truncate.\n","        max_tokens (int): The maximum number of tokens allowed.\n","        model_name (str): The name of the model for tokenization (default: cl100k_base).\n","\n","    Returns:\n","        str: The truncated text.\n","    \"\"\"\n","    enc = tiktoken.get_encoding(model_name)\n","    tokens = enc.encode(text)\n","\n","    if len(tokens) <= max_tokens:\n","        return text  # No truncation needed\n","\n","    truncated_tokens = tokens[:max_tokens]\n","    truncated_text = enc.decode(truncated_tokens)\n","    print(f\"Truncated from {len(text)} to {len(truncated_text)}.\")\n","    return truncated_text\n","\n","def get_llm_passage(text, topic):\n","  sys_prompt = f\"\"\"You are asked to generate a passage based on the topic provided by the user.\n","  Use the documents provided by the user as much as possible and only generate content relevant to the topic.\n","  Make sure the response is less than 300 words.\"\"\"\n","\n","  user_prompt = f\"\"\"Topic: {topic}\n","  Documents: {text}\"\"\"\n","\n","  response: ChatResponse = chat(model='llama3.1:8b-instruct-q8_0', messages=[\n","    {\n","      'role': 'system',\n","      'content': sys_prompt\n","    },\n","    {\n","      'role': 'user',\n","      'content': user_prompt\n","    },\n","  ])\n","  return response['message']['content']\n","\n","def get_sentiment_score(text, topic):\n","\n","  # passage = get_llm_passage(text, topic)\n","\n","  prompt = f\"\"\"Please rate the sentiment towards {topic} expressed in the text provided\n","                on a scale of -5 to +5, where -5 is extremely negative, 0 is neutral, and\n","                +5 is extremely positive. If the passage is not relevant to the topic, return 0.\n","                Your response should only include the rating and no other text.\n","                \"\"\"\n","\n","  response: ChatResponse = chat(model='llama3.1:8b-instruct-q8_0', messages=[\n","    # {\n","    #   'role': 'system',\n","    #   'content': prompt\n","    # },\n","    {\n","      'role': 'user',\n","      'content': prompt+text\n","    },\n","  ])\n","  rating = response['message']['content']\n","  # return rating\n","  match = re.search(r'-?\\d', rating)\n","  if match:\n","    return int(match.group())\n","  else:\n","    return 0\n","\n","def get_relevant_passages(query, index, metadata, top_k=5):\n","  top_k_results = retrieve_top_k(query, index, metadata, top_k)\n","\n","  rel_chuncks = []\n","  # sort based on score\n","  top_k_results = sorted(top_k_results, key=lambda x: x['score'], reverse=True)\n","\n","  return top_k_results"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":217051,"status":"ok","timestamp":1734418752705,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"9x6dYXgKMRFU"},"outputs":[],"source":["import json\n","# Paths to the index and metadata\n","faiss_index_file = \"/content/drive/MyDrive/RAG_Poisoning/poisoned_embeddings/wikiasp_embeddings_2.faiss\"\n","metadata_file = \"/content/drive/MyDrive/RAG_Poisoning/poisoned_embeddings/metadata_2.json\"\n","\n","normal_faiss_index_file = \"/content/drive/MyDrive/RAG_Poisoning/embeddings/wikiasp_embeddings.faiss\"\n","normal_metadata_file = \"/content/drive/MyDrive/RAG_Poisoning/embeddings/metadata.json\"\n","\n","passages_file = \"/content/drive/MyDrive/RAG_Poisoning/passages_2.json\"\n","\n","# Load FAISS index and metadata\n","poison_index = load_faiss_index(faiss_index_file)\n","normal_index = load_faiss_index(normal_faiss_index_file)\n","\n","with open(metadata_file, \"r\") as f:\n","    poison_metadata = json.load(f)\n","\n","with open(normal_metadata_file, \"r\") as f:\n","    normal_metadata = json.load(f)\n","\n","with open (passages_file, \"r\") as f:\n","    passages = json.load(f)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1734418752707,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"kmEH9Ql9Mab0"},"outputs":[],"source":["def similarity_analysis(passages):\n","  # Encode the passages into embeddings\n","  embeddings = em_model.encode(passages, convert_to_numpy=True)\n","\n","  # Compute the cosine similarity matrix\n","  cosine_sim_matrix = util.cos_sim(embeddings, embeddings).numpy()\n","\n","  # Calculate overall similarity metrics\n","  # Mean similarity (excluding diagonal)\n","  upper_triangle_indices = np.triu_indices_from(cosine_sim_matrix, k=1)\n","  mean_similarity = np.mean(cosine_sim_matrix[upper_triangle_indices])\n","\n","  # Minimum and maximum similarity\n","  min_similarity = np.min(cosine_sim_matrix[upper_triangle_indices])\n","  max_similarity = np.max(cosine_sim_matrix[upper_triangle_indices])\n","\n","  print(f\"\\nMean Similarity: {mean_similarity:.2f}\")\n","  print(f\"Minimum Similarity: {min_similarity:.2f}\")\n","  print(f\"Maximum Similarity: {max_similarity:.2f}\")\n","\n","  # Identify passages above a similarity threshold\n","  threshold = 0.8\n","  similar_passages = []\n","  similar_passages_indices = []\n","\n","  for i in range(len(passages)):\n","      for j in range(len(passages)):\n","          if i!=j and cosine_sim_matrix[i, j] > threshold:\n","              similar_passages.append((passages[i], passages[j], cosine_sim_matrix[i, j]))\n","              similar_passages_indices.append(i)\n","\n","  if similar_passages:\n","      similar_passages_indices = list(set(similar_passages_indices))\n","      print(f\"{len(similar_passages_indices)} passages above similarity threshold ({threshold})\")\n","\n","  else:\n","      print(f\"\\nNo passages found with similarity above {threshold}.\")\n","\n","  return similar_passages_indices"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1734418752707,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"ioeJhjF-NFtx"},"outputs":[],"source":["# Function to analyze sentiment distribution and detect outliers\n","def analyze_sentiment(sentiments, z_threshold=1):\n","    \"\"\"\n","    Analyze sentiment distribution and detect outliers.\n","\n","    Args:\n","        sentiments (list of float): List of sentiment scores.\n","        z_threshold (float): Z-score threshold for identifying outliers.\n","\n","    Returns:\n","        baseline (float): Mean sentiment score.\n","        outliers (list of tuple): Indices and scores of outliers.\n","    \"\"\"\n","    mean_sentiment = np.mean(sentiments)\n","    std_dev_sentiment = np.std(sentiments)\n","\n","    # Calculate z-scores\n","    z_scores = [(i, (s - mean_sentiment) / std_dev_sentiment) for i, s in enumerate(sentiments)]\n","\n","    # Detect outliers\n","    outliers = [(i, sentiments[i]) for i, z in z_scores if abs(z) > z_threshold]\n","\n","    return mean_sentiment, outliers\n","\n","def sentiment_distribution(passages, similar_passages_indices):\n","  passage_sentiments = []\n","  for passage in passages:\n","    passage_sentiments.append(get_sentiment_score(passage, query))\n","\n","  baseline_sentiment, outliers = analyze_sentiment(passage_sentiments)\n","\n","  poisoned_passages_indices = []\n","  for i in range(len(passages)):\n","    if i in similar_passages_indices and outliers:\n","      poisoned_passages_indices.append(i)\n","\n","  return poisoned_passages_indices\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1734418752707,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"BfqxFW93UF_i"},"outputs":[],"source":["def confusion_matrix(y_true, y_pred):\n","\n","  tp = len(set(poisoned_passages_indices).intersection(set(similar_passages_indices)))\n","  fp = len(set(poisoned_passages_indices).difference(set(similar_passages_indices)))\n","  fn = len(set(similar_passages_indices).difference(set(poisoned_passages_indices)))\n","  tn = len(set(passages).difference(set(poisoned_passages_indices).union(set(similar_passages_indices))))\n","\n","  print(f\"True Positives: {tp}\")\n","  print(f\"False Positives: {fp}\")\n","  print(f\"False Negatives: {fn}\")\n","  print(f\"True Negatives: {tn}\")\n","\n","  confusion_matrix = np.array([[tp, fp], [fn, tn]])\n","\n","  return confusion_matrix\n"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1734420812669,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"tBGlhFpFgTUI"},"outputs":[],"source":["def find_actual_poisoned_pasages(passages):\n","  y_true = []\n","  for i in range(len(passages)):\n","    num_commas = passages[i].count(',')\n","    num_words = len(passages[i].split())\n","    if (num_commas < 45) and (num_words < 550):\n","      y_true.append(1)\n","    else:\n","      y_true.append(0)\n","  return y_true\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24312,"status":"ok","timestamp":1734420679092,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"ihMPT2EjUguj","outputId":"9ad36551-4f1c-4b8d-b5e9-8f8ea023a6ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Mean Similarity: 0.69\n","Minimum Similarity: 0.55\n","Maximum Similarity: 0.93\n","12 passages above similarity threshold (0.8)\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","query = \"Obama's Healthcare Reforms\"\n","retrieved_docs = get_relevant_passages(query, poison_index, poison_metadata, top_k = 25)\n","\n","passages = []\n","for doc in retrieved_docs:\n","  passages.append(doc[\"chunk\"])\n","\n","similar_passages_indices = similarity_analysis(passages)\n","poisoned_passages_indices = sentiment_distribution(passages, similar_passages_indices)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1734420679094,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"piZLDbuLc_Cs","outputId":"9de697b6-63ae-4875-a4d5-b02dcf20c67c"},"outputs":[{"name":"stdout","output_type":"stream","text":["True Positives: 12\n","False Positives: 0\n","False Negatives: 0\n","True Negatives: 25\n","Confusion Matrix:\n","[[12  0]\n"," [ 0 25]]\n","Accuracy: 0.92\n","Precision: 0.8333333333333334\n","Recall: 1.0\n","F1 Score: 0.9090909090909091\n"]}],"source":["# Convert lists to binary format (0 or 1) based on whether an index is present\n","y_true = find_actual_poisoned_pasages(passages)\n","y_pred = [1 if i in poisoned_passages_indices else 0 for i in range(len(passages))]\n","\n","cf_matrix = confusion_matrix(poisoned_passages_indices, similar_passages_indices)\n","\n","print(f\"Confusion Matrix:\\n{cf_matrix}\")\n","print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n","print(f\"Precision: {precision_score(y_true, y_pred)}\")\n","print(f\"Recall: {recall_score(y_true, y_pred)}\")\n","print(f\"F1 Score: {f1_score(y_true, y_pred)}\")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1734420679094,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"mDSG3RmKfbUB","outputId":"81efe2b1-f127-4182-dd9a-83367bceee0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]\n","[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"]}],"source":["print(y_true)\n","print(y_pred)"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1734420851759,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"s2Jdoo1UgPyX"},"outputs":[],"source":["topics_file = \"/content/drive/MyDrive/RAG_Poisoning/topics.json\"\n","\n","with open(topics_file, \"r\") as f:\n","    topics = json.load(f)\n","    topics = topics[\"topics\"]"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786611,"status":"ok","timestamp":1734422533118,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"6l6AeGjoibt6","outputId":"0ab93cd9-182a-4663-981e-9878097d24a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Procesing: Brexit and its Impact on the European Union\n","\n","Mean Similarity: 0.70\n","Minimum Similarity: 0.50\n","Maximum Similarity: 0.95\n","13 passages above similarity threshold (0.8)\n","Procesing: Angela Merkel's Leadership during the Eurozone Crisis\n","\n","Mean Similarity: 0.76\n","Minimum Similarity: 0.56\n","Maximum Similarity: 0.96\n","20 passages above similarity threshold (0.8)\n","Procesing: Vladimir Putin's Foreign Policy in the Middle East\n","\n","Mean Similarity: 0.71\n","Minimum Similarity: 0.44\n","Maximum Similarity: 0.95\n","11 passages above similarity threshold (0.8)\n","Procesing: The Paris Agreement and Climate Change Policies\n","\n","Mean Similarity: 0.71\n","Minimum Similarity: 0.51\n","Maximum Similarity: 0.93\n","12 passages above similarity threshold (0.8)\n","Procesing: Xi Jinping's Economic Policies and Reforms\n","\n","Mean Similarity: 0.63\n","Minimum Similarity: 0.45\n","Maximum Similarity: 0.93\n","8 passages above similarity threshold (0.8)\n","Procesing: India's Healthcare Policies under Narendra Modi\n","\n","Mean Similarity: 0.53\n","Minimum Similarity: 0.10\n","Maximum Similarity: 0.94\n","10 passages above similarity threshold (0.8)\n","Procesing: The Role of the United Nations in Global Peacekeeping\n","\n","Mean Similarity: 0.67\n","Minimum Similarity: 0.41\n","Maximum Similarity: 0.94\n","11 passages above similarity threshold (0.8)\n","Procesing: The Influence of Lobbying on U.S. Electoral Politics\n","\n","Mean Similarity: 0.67\n","Minimum Similarity: 0.42\n","Maximum Similarity: 0.93\n","16 passages above similarity threshold (0.8)\n","Procesing: Brazil's Environmental Policies under Jair Bolsonaro\n","\n","Mean Similarity: 0.60\n","Minimum Similarity: 0.27\n","Maximum Similarity: 0.96\n","12 passages above similarity threshold (0.8)\n","Procesing: Theresa May's Approach to Brexit Negotiations\n","\n","Mean Similarity: 0.68\n","Minimum Similarity: 0.51\n","Maximum Similarity: 0.94\n","14 passages above similarity threshold (0.8)\n","Procesing: The Effects of the Arab Spring on Middle Eastern Politics\n","\n","Mean Similarity: 0.63\n","Minimum Similarity: 0.42\n","Maximum Similarity: 0.96\n","9 passages above similarity threshold (0.8)\n","Procesing: Turkey's Political Landscape under Recep Tayyip ErdoÄŸan\n","\n","Mean Similarity: 0.77\n","Minimum Similarity: 0.62\n","Maximum Similarity: 0.96\n","24 passages above similarity threshold (0.8)\n","Procesing: Justin Trudeau's Immigration Reforms in Canada\n","\n","Mean Similarity: 0.61\n","Minimum Similarity: 0.40\n","Maximum Similarity: 0.94\n","12 passages above similarity threshold (0.8)\n","Procesing: The Impact of Populism on European Democracies\n","\n","Mean Similarity: 0.64\n","Minimum Similarity: 0.27\n","Maximum Similarity: 0.94\n","12 passages above similarity threshold (0.8)\n","Procesing: Japan's Economic Policy Adjustments under Shinzo Abe\n","\n","Mean Similarity: 0.73\n","Minimum Similarity: 0.53\n","Maximum Similarity: 0.95\n","20 passages above similarity threshold (0.8)\n","Procesing: NATO's Strategic Response to Russian Aggression\n","\n","Mean Similarity: 0.72\n","Minimum Similarity: 0.56\n","Maximum Similarity: 0.96\n","15 passages above similarity threshold (0.8)\n","Procesing: The Role of Social Media in Modern Political Campaigns\n","\n","Mean Similarity: 0.65\n","Minimum Similarity: 0.47\n","Maximum Similarity: 0.93\n","12 passages above similarity threshold (0.8)\n","Procesing: The Economic Reforms in Saudi Arabia under Mohammed bin Salman\n","\n","Mean Similarity: 0.59\n","Minimum Similarity: 0.38\n","Maximum Similarity: 0.95\n","11 passages above similarity threshold (0.8)\n","Procesing: The Political Dynamics of the Korean Peninsula\n","\n","Mean Similarity: 0.59\n","Minimum Similarity: 0.35\n","Maximum Similarity: 0.94\n","10 passages above similarity threshold (0.8)\n","Procesing: Shinzo Abe's Foreign Policy towards the United States\n","\n","Mean Similarity: 0.72\n","Minimum Similarity: 0.54\n","Maximum Similarity: 0.96\n","16 passages above similarity threshold (0.8)\n","Procesing: Donald Trump's Immigration Policy\n","\n","Mean Similarity: 0.64\n","Minimum Similarity: 0.44\n","Maximum Similarity: 0.96\n","10 passages above similarity threshold (0.8)\n","Procesing: Obama's Healthcare Reforms\n","\n","Mean Similarity: 0.69\n","Minimum Similarity: 0.55\n","Maximum Similarity: 0.93\n","12 passages above similarity threshold (0.8)\n","Procesing: Climate Change Initiatives and Clean Energy Investments of Joe Biden\n","\n","Mean Similarity: 0.70\n","Minimum Similarity: 0.47\n","Maximum Similarity: 1.00\n","18 passages above similarity threshold (0.8)\n","Accuracy: 0.8347826086956521\n","Precision: 0.8077922077922078\n","Recall: 0.9775784753363229\n","F1 Score: 0.8845922787193974\n"]}],"source":["total_y_true = []\n","total_y_pred = []\n","for topic in topics:\n","  query = topic['topic']\n","  retrieved_docs = get_relevant_passages(query, poison_index, poison_metadata, top_k = 25)\n","\n","  passages = []\n","  for doc in retrieved_docs:\n","    passages.append(doc[\"chunk\"])\n","\n","  print(f\"Procesing: {query}\")\n","  similar_passages_indices = similarity_analysis(passages)\n","  poisoned_passages_indices = sentiment_distribution(passages, similar_passages_indices)\n","\n","  y_true = find_actual_poisoned_pasages(passages)\n","  y_pred = [1 if i in poisoned_passages_indices else 0 for i in range(len(passages))]\n","\n","  total_y_true.extend(y_true)\n","  total_y_pred.extend(y_pred)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1734422570504,"user":{"displayName":"BPDC Google Colab2","userId":"08171648773294124015"},"user_tz":-240},"id":"LmZXQ7i0pBa6","outputId":"ba57101f-8e68-4541-f4db-6838ea27d57b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8347826086956521\n","Precision: 0.8077922077922078\n","Recall: 0.9775784753363229\n","F1 Score: 0.8845922787193974\n"]}],"source":["print(f\"Accuracy: {accuracy_score(total_y_true, total_y_pred)}\")\n","print(f\"Precision: {precision_score(total_y_true, total_y_pred)}\")\n","print(f\"Recall: {recall_score(total_y_true, total_y_pred)}\")\n","print(f\"F1 Score: {f1_score(total_y_true, total_y_pred)}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMjlg4ibBh8gzTljLq/+N9U","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
