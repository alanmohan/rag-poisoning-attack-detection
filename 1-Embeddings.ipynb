{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi0ufAMsrmDs",
        "outputId": "a61458c5-5b11-48b7-b2a8-3ed0985e37c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49R0mfqOr3xS",
        "outputId": "d4a7f93e-12d8-4f2c-ea2c-df9056f14768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7E37OG4ru5v",
        "outputId": "5c548a9c-0640-438a-ec0d-4b9210df86c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDbHxdYBrw-x"
      },
      "outputs": [],
      "source": [
        "# Set up paths and model\n",
        "dataset_files = {\n",
        "    \"train\": \"/content/drive/MyDrive/RAG_Poisoning/wikiasp_dataset/train.jsonl\",\n",
        "    \"valid\": \"/content/drive/MyDrive/RAG_Poisoning/wikiasp_dataset/valid.jsonl\",\n",
        "    \"test\": \"/content/drive/MyDrive/RAG_Poisoning/wikiasp_dataset/test.jsonl\"\n",
        "}\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "faiss_index_file = \"/content/drive/MyDrive/RAG_Poisoning/embeddings/wikiasp_embeddings.faiss\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmZMgZB_qobW",
        "outputId": "ca98fe47-1c93-44a1-af27-deef81557a65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load MiniLM-L6-V2 model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ZOMwPbqrR0",
        "outputId": "737a1c36-7037-419e-d006-4234c46ac61d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing train split: 100%|██████████| 18177/18177 [23:29<00:00, 12.90it/s]\n",
            "Processing valid split: 100%|██████████| 2218/2218 [03:02<00:00, 12.15it/s] \n",
            "Processing test split: 100%|██████████| 2333/2333 [03:05<00:00, 12.56it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index saved to /content/drive/MyDrive/RAG_Poisoning/embeddings/wikiasp_embeddings.faiss\n",
            "Metadata saved to /content/drive/MyDrive/RAG_Poisoning/embeddings/metadata.json\n"
          ]
        }
      ],
      "source": [
        "# Load MiniLM-L6-V2 model\n",
        "model = SentenceTransformer(embedding_model, device=\"cuda\")  # Ensure GPU usage\n",
        "\n",
        "# Function to chunk text into smaller parts\n",
        "def chunk_text(sentences, chunk_size=64, stride=16):\n",
        "    \"\"\"Chunks input text with overlap for better embedding coverage.\"\"\"\n",
        "    chunks = []\n",
        "    for i in range(0, len(sentences), stride):\n",
        "        chunk = sentences[i:i + chunk_size]\n",
        "        if len(chunk) > 0:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "# Function to process a single instance\n",
        "def process_instance(instance):\n",
        "    exid = instance[\"exid\"]\n",
        "    sentences = instance[\"inputs\"]\n",
        "    targets = instance[\"targets\"]\n",
        "\n",
        "    # Chunk the input sentences\n",
        "    chunks = chunk_text(sentences)\n",
        "\n",
        "    # Generate embeddings for each chunk\n",
        "    embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=False)\n",
        "\n",
        "    # Create metadata for each embedding\n",
        "    metadata = [\n",
        "        {\n",
        "            \"exid\": exid,\n",
        "            \"chunk_id\": i,\n",
        "            \"targets\": targets,\n",
        "            \"chunk\": chunks[i]\n",
        "        }\n",
        "        for i in range(len(embeddings))\n",
        "    ]\n",
        "\n",
        "    return embeddings, metadata\n",
        "\n",
        "# Function to process dataset with parallel processing\n",
        "def process_dataset(dataset_files, model, faiss_index_file, max_workers=8):\n",
        "    all_embeddings = []\n",
        "    metadata = []\n",
        "    dimension = None\n",
        "\n",
        "    # Thread pool for parallel processing\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        for split, filepath in dataset_files.items():\n",
        "            if not os.path.exists(filepath):\n",
        "                print(f\"File {filepath} not found, skipping.\")\n",
        "                continue\n",
        "\n",
        "            with open(filepath, 'r') as file:\n",
        "                lines = file.readlines()\n",
        "                instances = [json.loads(line) for line in lines]\n",
        "\n",
        "                # Parallelize instance processing\n",
        "                results = list(\n",
        "                    tqdm(\n",
        "                        executor.map(process_instance, instances),\n",
        "                        total=len(instances),\n",
        "                        desc=f\"Processing {split} split\"\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                for embeddings, meta in results:\n",
        "                    all_embeddings.append(embeddings)\n",
        "                    metadata.extend(meta)\n",
        "\n",
        "    # Combine all embeddings into a single array\n",
        "    all_embeddings = np.vstack(all_embeddings).astype('float32')\n",
        "    dimension = all_embeddings.shape[1]\n",
        "\n",
        "    # Combine all metadata\n",
        "    # Create FAISS index\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 distance-based index\n",
        "    index = faiss.IndexIDMap(index)  # Use ID map for metadata lookup\n",
        "\n",
        "    # Add embeddings to the FAISS index\n",
        "    ids = np.arange(len(all_embeddings)).astype('int64')  # Unique IDs for each embedding\n",
        "    index.add_with_ids(all_embeddings, ids)\n",
        "\n",
        "    # Save the index\n",
        "    faiss.write_index(index, faiss_index_file)\n",
        "    print(f\"FAISS index saved to {faiss_index_file}\")\n",
        "\n",
        "    # Save metadata to a JSON file\n",
        "    metadata_file = \"/content/drive/MyDrive/RAG_Poisoning/embeddings/metadata.json\"\n",
        "    with open(metadata_file, \"w\") as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    print(f\"Metadata saved to {metadata_file}\")\n",
        "\n",
        "\n",
        "# Run the processing\n",
        "process_dataset(dataset_files, model, faiss_index_file, max_workers=256)  # Adjust max_workers as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFF6Daga4YRC"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "em_model = SentenceTransformer(embedding_model, device=\"cuda\")  # Use GPU for encoding\n",
        "\n",
        "# Function to load FAISS index\n",
        "def load_faiss_index(index_file):\n",
        "    \"\"\"Loads the FAISS index from a file.\"\"\"\n",
        "    index = faiss.read_index(index_file)\n",
        "    return index\n",
        "\n",
        "# Function to perform retrieval\n",
        "def retrieve_top_k(query, index, metadata, top_k=5):\n",
        "    \"\"\"\n",
        "    Retrieve top-k similar documents for a given query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        index (faiss.Index): The FAISS index.\n",
        "        metadata (list[dict]): Metadata corresponding to the embeddings in the index.\n",
        "        top_k (int): Number of top results to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: Top-k metadata entries with similarity scores.\n",
        "    \"\"\"\n",
        "    # Encode the query into an embedding\n",
        "    query_embedding = em_model.encode([query], convert_to_numpy=True)\n",
        "\n",
        "    # Search the FAISS index\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Collect results\n",
        "    results = []\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        if idx == -1:  # FAISS returns -1 for missing indices\n",
        "            continue\n",
        "        results.append({\n",
        "            \"score\": distances[0][i],\n",
        "            **metadata[idx]\n",
        "        })\n",
        "    return results\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cfb76f11de74081b6a90674839154a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d608c2eb13b4efb8eac233d564eb76a",
              "IPY_MODEL_4edd8dbd61cb489cb9c375a1854830dd",
              "IPY_MODEL_4c7c54e832924b8fb7e32094b3bcbbc7"
            ],
            "layout": "IPY_MODEL_982848b84d27442eb847f9c6a21c3c9a"
          }
        },
        "2d608c2eb13b4efb8eac233d564eb76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc7d669199c4f4d9025639216770c74",
            "placeholder": "​",
            "style": "IPY_MODEL_dfab354d46ef4d248baf53577536df27",
            "value": "Loading checkpoint shards:  25%"
          }
        },
        "369ce9dd177249cb8b583bd9e107a3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c7c54e832924b8fb7e32094b3bcbbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb88cd30f9544ad3b9dfd2d6dceabedd",
            "placeholder": "​",
            "style": "IPY_MODEL_369ce9dd177249cb8b583bd9e107a3e3",
            "value": " 1/4 [01:19&lt;02:26, 48.97s/it]"
          }
        },
        "4edd8dbd61cb489cb9c375a1854830dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09c78a96b8d4e439468ca610da7b3ae",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d652898de3174801acbd635bb9439ad8",
            "value": 1
          }
        },
        "7fc7d669199c4f4d9025639216770c74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982848b84d27442eb847f9c6a21c3c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09c78a96b8d4e439468ca610da7b3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb88cd30f9544ad3b9dfd2d6dceabedd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d652898de3174801acbd635bb9439ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfab354d46ef4d248baf53577536df27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
